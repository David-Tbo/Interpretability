{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAPLEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd S. Shapley  \n",
    "A Value for n-person games.  \n",
    "In contribution to the Theory of Games  \n",
    "(Annals of mathematical Studies), 1953."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:  \n",
    "- https://arxiv.org/pdf/1705.07874\n",
    "- https://christophm.github.io/interpretable-ml-book/shap.html\n",
    "- https://www.quantmetry.com/blog/valeurs-de-shapley/  \n",
    "- https://www.youtube.com/watch?v=tuE875uid1c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Reminders  \n",
    "\n",
    "- <u>Subset</u>  \n",
    "\n",
    "The number of subsets in a set with $n$ elements is $2^n$\n",
    "\n",
    "- <u>Combinations</u>  \n",
    "\n",
    "In combinatorics, the symbol $ C(n, k) $ or $ \\binom{n}{k} $ represents the number of combinations of $ k $ elements from $ n $ elements, <u>without considering the order</u>, of the chosen elements.  \n",
    "\n",
    "$ C(n, k) = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} $\n",
    "\n",
    "- <u>Permutations</u>  \n",
    "\n",
    "When the order matters, we speak of permutations. The number of permutations of $k$ elements from $n$ elements is given by the following formula:  :  \n",
    "\n",
    "$ P(n, k) = \\frac{n!}{(n-k)!} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Shapley Values</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP explanation method computes Shapley values based on coalitional game theory.  \n",
    "\n",
    "**The Shapley Value of a feature value is its contribution to its payout weighted and summede over all hte possible feature value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shapley values are a method for explaining machine learning models that helps to understand the importance of each feature for a specific prediction.**  \n",
    "The goal of SHAP in Machine Learning is to explain the prediction of an instance $x$ by computing the contribution of each feature to the prediction.  \n",
    "\n",
    " and assign a value to each feature based on its contribution to the prediction.  \n",
    "\n",
    "This SHAP targets the complexe models, black-box models. For the others - linear regression model for example - the explanation is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Theory Approach\n",
    "\n",
    "[Youtube Link: Michael J. Pyrcz, The University of Texas at Austing](https://www.youtube.com/watch?v=oCIybnawLdg&list=PLtZXy3uciru6ld9K2Sj44EvjGnY7tR-H9&index=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game Theory Approach:  \n",
    "\n",
    "- Based on the Shapley value for allocating resources between 'players' based on a summarization of marginal contributions. Dividing payment between players.  \n",
    "\n",
    "$\\text{Marginal Contribution } =\\text{ Resource with } i^{th} \\text{ Player - Resource without } i^{th} \\text{Player}$.  \n",
    "\n",
    "The Marginal Contribution are weighted to obtain the gain to the total contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXEMPLE: Two people join and work together to sell a software:**  \n",
    "\n",
    "**<u>Case 1:</u>**  \n",
    "If the $person_1$ works alone on the project he owns $50,000. If the $person_2$ works alone, he owns $75,000.  \n",
    "And if they work together, they own $125,000.\n",
    "Which can write as:\n",
    "\n",
    "- $f(person_1) =$ $50,000  \n",
    "- $f(person_2) =$ $75,000  \n",
    "- $f(person_1, person_2) =$ $125,000  \n",
    "\n",
    "$\\Rightarrow$ Marginal contribution of player 1:  \n",
    "\n",
    "$\\frac{1}{2}(f(person_1) - f(\\emptyset)) + \\frac{1}{2}(f(person_1, person_2) - f(person_2)) $  \n",
    "$= \\frac{1}{2}(50000 - 0) + \\frac{1}{2}(125000 - 75000) = 25000 + 25000 = 50000$\n",
    "\n",
    "$\\Rightarrow$ Marginal contribution of player 2:  \n",
    "\n",
    "$\\frac{1}{2}(f(person_2) - f(\\emptyset)) + \\frac{1}{2}(f(person_1, person_2) - f(person_1)) $  \n",
    "$= \\frac{1}{2}(75000 - 0) + \\frac{1}{2}(125000 - 50000) = 37500 + 37500 = 75000$\n",
    "\n",
    "As we could intuitively think, in this case the sum works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Exercice: </u>**  \n",
    "\n",
    "Do the same for the next two cases:  \n",
    "\n",
    "- <u>Case 2: (synergy)</u>  \n",
    "If the $person_1$ works alone on the project he owns $30,000. If the $person_2$ works alone, he owns $70,000.  \n",
    "And if they work together, they own $120,000.  \n",
    "In this case, the persons will have a better profit than alone due to synergy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>Case 3: (dysergy!)</u>  \n",
    "Exercice: What would happen if the $person_1$ works alone on the project he owns $30,000.  \n",
    "If the $person_2$ works alone, he owns $70,000. If they work together, they own $80,000 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Shapley values tell us how to fairly distribute the gain (prediction) among the players (features).</u>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal contribution in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the income, we have a linear regression model define as : $f(x_1, x_2) = 200 x_1 + 1000 x_2$  \n",
    "\n",
    "Where $x_1$ is the age $\\in [18, 60]$ and $x_2$ is the degree $\\in \\{0,1\\}$ ($0$: no degree, $1$: degree).  \n",
    "\n",
    "If we have an instance $x_1$ with $Age = 20$ and $degree = 1$, the predicted income is $200 \\times 20 + 1000 \\times 1 = 4000 + 1000 = 5000$  \n",
    "\n",
    "**What is the marginal contribution of degree {2} to the coalition of age {1} ?**  \n",
    "\n",
    "Reminder, the general formula : $v_x(S) = \\int f(x_1,\\ldots, x_p) dP_{x \\notin S}$  \n",
    "\n",
    "In our case:  \n",
    "\n",
    "$v_x(\\{1\\}) = \\int f(20, x_2) dP_{x_2} = \\underset{i \\in \\{0,1\\}}{\\sum}f(20,i)\\mathbb{P}(x_2=i) $  \n",
    "$= f(20,0)\\mathbb{P}(x_2=0) + f(20,1)\\mathbb{P}(x_2=1) = (200 \\times 20 + 1000 \\times 0)\\frac{1}{2} + (200 \\times 20 + 1000 \\times 1)\\frac{1}{2} $  \n",
    "$= (4000 + 0)\\frac{1}{2} + (4000 + 1000)\\frac{1}{2} = 2000 + 2500 = 4500$  \n",
    "\n",
    "$v_x(\\{1, 2\\}) = f(20, 1) = 200 \\times 20 + 1000 \\times 1 = 4000 + 1000 = 5000$  \n",
    "\n",
    "$v_x(\\{1, 2\\}) - v_x(\\{1\\}) = 5000 - 4500 = 500$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Value formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\phi_i(v) = \\underset{S \\subseteq N \\setminus \\{i\\}}{\\sum}\\frac{|S|! \\times (|N| - |S| - 1)!}{|N|!}(v(S \\cup \\{i\\}) - v(S))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\phi_i(v)$: The Shapley value for player $i$ in the game with characteristic function $v$.\n",
    "- $S$: A subset of the set of players $N$ excluding player $i$.\n",
    "- $N \\setminus \\{i\\}$: The set of all players except player $i$.\n",
    "- $|S|$: The number of players in subset $S$.\n",
    "- $|N|$: The total number of players.\n",
    "- $|S|!$: The factorial of the number of players in subset $S$.\n",
    "- $(|N| - |S| - 1)!$: The factorial of the number of players not in subset $S$ and excluding player $i$.\n",
    "- $|N|!$: The factorial of the total number of players.\n",
    "- $v(S \\cup \\{i\\})$: The value of the characteristic function $v$ for the coalition $S$ including player $i$.\n",
    "- $v(S)$: The value of the characteristic function $v$ for the coalition $S$ excluding player $i$.\n",
    "\n",
    "- $v(S \\cup \\{i\\}) - v(S)$: The marginal contribution of player $i$ to the coalition $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite the formula:  \n",
    "\n",
    "$\\phi_i(v) = \\underset{S \\subseteq N \\setminus \\{i\\}}{\\sum}\\frac{|S|! \\times (|N| - |S| - 1)!}{|N| \\times |N - 1|!}(v(S \\cup \\{i\\}) - v(S)) $  \n",
    "\n",
    "$\\phi_i(v) = \\frac{1}{|N|}\\underset{S \\subseteq N \\setminus \\{i\\}}{\\sum}\\frac{|S|! \\times (|N| - |S| - 1)!}{|N - 1|!}(v(S \\cup \\{i\\}) - v(S)) $  \n",
    "\n",
    "$$\\phi_i(v) = \\frac{1}{|N|}\\underset{S \\subseteq N \\setminus \\{i\\}}{\\sum}\\binom{|N - 1|}{|S|}^{-1}(v(S \\cup \\{i\\}) - v(S))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>NB</u>: $\\emptyset \\subseteq N \\setminus \\{i\\}$ the first term of the Shapley Value should be : $\\frac{1}{|N|} \\ [\\binom{|N - 1|}{|\\emptyset|}^{-1} \\ (v(\\emptyset \\cup \\{i\\}) - v(\\emptyset) + \\ldots)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to understand the computation of the weights](https://ichi.pro/fr/comprendre-les-valeurs-de-shapley-242337773307368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily show with examples that:  \n",
    "\n",
    "1. The order in which the players are placed (1,2,3), (1,3,2) ... impact the contribution. To neutralize this effect, we average the marginal contributions by : $\\binom{|N - 1|}{|S|}^{-1}$.  \n",
    "\n",
    "2. The sequence where the features are intgrated also impact the contributions, to neutralize this second effect, we average the marginal contribution over the combinatorial of sequence with: $\\frac{1}{|N|}$  \n",
    "\n",
    "[Henrik Sternberg - Exemples of how the order impact the contribution](https://www.youtube.com/watch?v=9KP0CdWMi64&list=PLtZXy3uciru6ld9K2Sj44EvjGnY7tR-H9&index=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In Machine Learning, $v()$ is the $predict()$ function, players are the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fair distribution\n",
    "\n",
    "### The 4 + 1 axiomes\n",
    "\n",
    "- **<u>Efficiency:</u>**  \n",
    "\n",
    "The prediction is divided among the features:  \n",
    "\n",
    "$\\sum_{i=1}^p \\phi_{i} = \\hat{f}(x) - \\mathbb{E}[f(X)]$\n",
    "\n",
    "- **<u>Null player:</u>**  \n",
    "\n",
    "A player will have a null Shapley Value if its contributions never change the gain.  \n",
    "In that case in Machine Learning, the feature not use in the model won't have a Shapley Value.\n",
    "\n",
    "- **<u>Symmetry:</u>**  \n",
    "\n",
    "Two players are interchangeable if they make the same contribution to every coalition. They will have equal share.  \n",
    "In Machine Learning, two features will have the same Shapley Value if they make the same contributions to all the coalitions.  \n",
    "\n",
    "$f(S \\cup \\{j\\}) = f(S \\cup \\{k\\}), \\forall S \\subseteq \\{1\\ldots p\\} \\setminus \\{i,k\\} \\Rightarrow \\phi_j = \\phi_k$  \n",
    "\n",
    "The weighting ensures that Shapley values are symmetric, meaning that the order in which features are added does not change the Shapley values.  \n",
    "\n",
    "- **<u>Additivity:</u>**  \n",
    "\n",
    "Total gain for 2 games is equal to the sum of the gain on game 1 and on game 2.  \n",
    "\n",
    "The weighting ensures that Shapley values are additive, meaning that the sum of the Shapley values of all features is equal to the difference  \n",
    "between the value of the prediction function for the complete set of features and the value of the prediction function for the empty set.\n",
    "\n",
    "- **<u>Consistency:</u>**  \n",
    "\n",
    "If we change of model and the marginal contribution of the feature changes, then the feature Shapley Value will change in the same direction.  \n",
    "We can reliably compare the Shapley Value of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapley Values are the unique solution to the properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have definied the Shapley Values, to use them in a Machine Learning context, one problem is coming, the computation time !  \n",
    "\n",
    "As for instance with a set of 32 features, there are $2^{32}$ subsets ! The computation will be RAM killer.  \n",
    "\n",
    "We'll see how to deal with it in the next Part of these Shapley Values notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
