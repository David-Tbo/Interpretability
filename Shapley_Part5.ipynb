{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Shapley Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **First we need a complex model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Access the features and target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Access the feature names and target names\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names\n",
    "\n",
    "# Create a DataFrame for the features\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "df['target'] = y\n",
    "\n",
    "# train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# We keep only the four first columns:\n",
    "\n",
    "X_train = X_train.iloc[:,:4]\n",
    "X_test = X_test.iloc[:, :4]\n",
    "\n",
    "# Create a DataFrame LightGBM for the train & test dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Define the model parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 100\n",
    "model = lgb.train(params, train_data, num_round, valid_sets=[test_data], )\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Convert the probabilities in binary classes\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **SHAP values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 455 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd95e6251be34a29bec715d16de7bfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Create the Kernel SHAP explainer (LIME + kernel)\n",
    "explainer = shap.KernelExplainer(model.predict, X_train, link ='logit', algorithm ='linear')\n",
    "\n",
    "# Compute the SHAP values for each instance of X_test. \n",
    "# The SHAP values is estimated based on a sample of size 100, that will be averaged.\n",
    "shap_values = explainer.shap_values(X_test, nsamples = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Shapley values to explain the predictions of a complex model is a powerful method for making models interpretable.  \n",
    "\n",
    "However, evaluating the performance of Shapley values in this context can be a bit more subtle than evaluating the performance of a traditional machine learning model.  \n",
    "\n",
    "Here are some approaches to evaluate the performance of Shapley values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Performances of Shapley ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Consistency with Expectations\n",
    "\n",
    "Check if the Shapley values align with your expectations based on your domain knowledge.  \n",
    "For example, if you know that a certain feature should have a significant impact on the prediction, the Shapley values should reflect that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Comparison with Other Explanation Methods\n",
    "\n",
    "Compare the Shapley values with other model explanation methods, such as LIME (Local Interpretable Model-agnostic Explanations) or feature weights in simpler models.  \n",
    "If the explanations are consistent across different methods, it strengthens confidence in the Shapley values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Quantitative Evaluation\n",
    "\n",
    "Use quantitative metrics to evaluate the performance of Shapley values. Here are some commonly used metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1. Fidelity  \n",
    "\n",
    "Measure the fidelity of the explanations by comparing the predictions of the original model with the predictions of a simplified model based on the Shapley values.  \n",
    "High fidelity means that the explanations are close to the actual predictions of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# Supposons que vous avez un modèle 'model' et des données 'X'\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# Calculer la fidélité\n",
    "def fidelity(model, X, shap_values):\n",
    "    original_predictions = model.predict(X)\n",
    "    shap_predictions = np.sum(shap_values.values, axis=1) + shap_values.base_values\n",
    "    return np.mean((original_predictions - shap_predictions) ** 2)\n",
    "\n",
    "fidelity_score = fidelity(model, X, shap_values)\n",
    "print(f\"Fidelity score: {fidelity_score}\")\n",
    "```\n",
    "\n",
    "#### b. **Stabilité**\n",
    "Mesurez la stabilité des Shapley values en calculant les valeurs pour des échantillons légèrement perturbés. Les Shapley values devraient être relativement stables pour des échantillons similaires.\n",
    "\n",
    "```python\n",
    "def stability(model, X, shap_values, perturbation_size=0.01):\n",
    "    perturbed_X = X + np.random.normal(0, perturbation_size, X.shape)\n",
    "    perturbed_shap_values = explainer(perturbed_X)\n",
    "    return np.mean((shap_values.values - perturbed_shap_values.values) ** 2)\n",
    "\n",
    "stability_score = stability(model, X, shap_values)\n",
    "print(f\"Stability score: {stability_score}\")\n",
    "```\n",
    "\n",
    "### 4. **Évaluation qualitative**\n",
    "Impliquez des experts du domaine pour évaluer qualitativement les explications fournies par les Shapley values. Les experts peuvent fournir des insights sur la pertinence et la précision des explications.\n",
    "\n",
    "### 5. **Visualisation**\n",
    "Utilisez des visualisations pour inspecter les Shapley values. Les graphiques de dépendance, les graphiques de résumé et les graphiques de force peuvent aider à comprendre l'impact des différentes caractéristiques sur les prédictions.\n",
    "\n",
    "```python\n",
    "# Graphique de résumé\n",
    "shap.summary_plot(shap_values, X)\n",
    "\n",
    "# Graphique de dépendance\n",
    "shap.dependence_plot(\"feature_name\", shap_values.values, X)\n",
    "\n",
    "# Graphique de force\n",
    "shap.force_plot(explainer.expected_value, shap_values.values, X)\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "Évaluer la performance des Shapley values dans le contexte de l'interprétabilité des modèles nécessite une combinaison de méthodes quantitatives et qualitatives. En utilisant des métriques comme la fidélité et la stabilité, en comparant avec d'autres méthodes d'explication, et en impliquant des experts du domaine, vous pouvez obtenir une évaluation complète de la performance des Shapley values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting bias with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting bias with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "gender_cols = [col for col in X_train.columns if 'Gender' in col] + [\"Trans\"]\n",
    "\n",
    "gender_features_locs = [X_train.columns.get_loc(col) for col in gender_cols]\n",
    "\n",
    "def describe_stats(gender_col):\n",
    "    s = stats.describe(shap_values[X_train[gender_col]][:,gender_features_locs].sum(axis=1))\n",
    "    return (gender_col, int(s.nobs), float(s.minmax[0]), float(s.minmax[1]), float(s.mean))\n",
    "\n",
    "display(pd.DataFrame([describe_stats(col) for col in gender_cols], [\"gender_col\", \"n\", \"min\", \"max\", \"mean\"]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
